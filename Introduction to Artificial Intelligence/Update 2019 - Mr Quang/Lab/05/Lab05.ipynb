{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the dataset CustomerChurn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  State  Account length  Area code International plan Voice mail plan  \\\n",
       "0    KS             128        415                 No             Yes   \n",
       "1    OH             107        415                 No             Yes   \n",
       "2    NJ             137        415                 No              No   \n",
       "3    OH              84        408                Yes              No   \n",
       "4    OK              75        415                Yes              No   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   Total night minutes  Total night calls  Total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   Customer service calls  Churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "OriginalCustomerChurn = pd.read_csv(\"CustomerChurn.csv\")\n",
    "OriginalCustomerChurn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data with encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function GetEncodeData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import copy\n",
    "\n",
    "def getEncodeData(DataFrame, Columns):\n",
    "    labelEncoder = LabelEncoder()\n",
    "    encodedData = copy.deepcopy(DataFrame)\n",
    "    for column in Columns:\n",
    "        encodedData[column] = labelEncoder.fit_transform(DataFrame[column])\n",
    "    return encodedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Account length</th>\n",
       "      <th>Area code</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Voice mail plan</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total day minutes</th>\n",
       "      <th>Total day calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve calls</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total night minutes</th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Total night charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>197.4</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>195.5</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>121.2</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>61.9</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>148.3</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  Account length  Area code  International plan  Voice mail plan  \\\n",
       "0     16             128        415                   0                1   \n",
       "1     35             107        415                   0                1   \n",
       "2     31             137        415                   0                0   \n",
       "3     35              84        408                   1                0   \n",
       "4     36              75        415                   1                0   \n",
       "\n",
       "   Number vmail messages  Total day minutes  Total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   Total day charge  Total eve minutes  Total eve calls  Total eve charge  \\\n",
       "0             45.07              197.4               99             16.78   \n",
       "1             27.47              195.5              103             16.62   \n",
       "2             41.38              121.2              110             10.30   \n",
       "3             50.90               61.9               88              5.26   \n",
       "4             28.34              148.3              122             12.61   \n",
       "\n",
       "   Total night minutes  Total night calls  Total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   Total intl minutes  Total intl calls  Total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   Customer service calls  Churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encodedData = getEncodeData(OriginalCustomerChurn, ['State', 'International plan', 'Voice mail plan'])\n",
    "encodedData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train data and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SplitDataFrameToTrainAndTest function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitDataFrameToTrainAndTest(DataFrame, TrainDataRate, TargetAtt):\n",
    "    training = DataFrame.sample(frac=TrainDataRate, random_state=1)\n",
    "    testing = DataFrame.loc[~DataFrame.index.isin(training.index)]\n",
    "    x_train = training.drop(TargetAtt, 1)\n",
    "    y_train = training[TargetAtt]\n",
    "    x_test = testing.drop(TargetAtt, 1)\n",
    "    y_test = testing[TargetAtt]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = SplitDataFrameToTrainAndTest(DataFrame=encodedData, TrainDataRate=0.6, TargetAtt='Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def RandomForestLearning(DataTrain, TargetTrain):\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(DataTrain, TargetTrain)\n",
    "    return rf\n",
    "\n",
    "def RandomForestTesting(RFModel, DataTest, TargetTest):\n",
    "    PredictTestRF = RFModel.predict(DataTest)\n",
    "    AccuracyRF = accuracy_score(TargetTest, PredictTestRF)\n",
    "    return AccuracyRF, PredictTestRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9392348087021756\n",
      "Predict:  [False False False ... False  True False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuant\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rfModel = RandomForestLearning(x_train, y_train)\n",
    "accuracy, predictTest = RandomForestTesting(rfModel, x_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Predict: ', predictTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuant\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RFRegressorModel = RandomForestRegressor(random_state= 1, max_depth= 10)\n",
    "RFRegressorModel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01565064, 0.01441812, 0.00467682, 0.07986064, 0.02823744,\n",
       "       0.03937743, 0.13720885, 0.02013832, 0.13507671, 0.06723363,\n",
       "       0.01722386, 0.07449385, 0.02382132, 0.03038056, 0.02969631,\n",
       "       0.06128489, 0.07576706, 0.04072794, 0.10472562])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFRegressorModel.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x24ca1bd0be0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_importances = pd.Series(RFRegressorModel.feature_importances_, index=x_train.columns).sort_values()\n",
    "feat_importances.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Account length', 0.014418124952522421),\n",
       " ('Area code', 0.0046768209412359025),\n",
       " ('Customer service calls', 0.10472561542210537),\n",
       " ('International plan', 0.07986063666996161),\n",
       " ('Number vmail messages', 0.0393774251166503),\n",
       " ('State', 0.01565064002377705),\n",
       " ('Total day calls', 0.020138322706779576),\n",
       " ('Total day charge', 0.13507670788015635),\n",
       " ('Total day minutes', 0.13720885231216917),\n",
       " ('Total eve calls', 0.017223860385455942),\n",
       " ('Total eve charge', 0.07449385355154196),\n",
       " ('Total eve minutes', 0.06723362920390134),\n",
       " ('Total intl calls', 0.07576705755962682),\n",
       " ('Total intl charge', 0.04072793522355549),\n",
       " ('Total intl minutes', 0.061284893338492394),\n",
       " ('Total night calls', 0.03038055779046297),\n",
       " ('Total night charge', 0.029696312878524617),\n",
       " ('Total night minutes', 0.023821317976935215),\n",
       " ('Voice mail plan', 0.02823743606614555)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mapped = zip(x_train.columns, RFRegressorModel.feature_importances_)\n",
    "mapped = set(mapped)\n",
    "display(mapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.944\n",
      "Time:  0.08078360557556152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xuant\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def PrintTrainTestInformation(x_train, y_train, x_test, y_test):\n",
    "    print(\"Train rows and colums: \", x_train.shape)\n",
    "    print(\"Test rows and colums: \", x_test.shape)\n",
    "    x_train_feselection02,y_train_feselection02,x_test_feselection02,y_test_feselection02 = SplitDataFrameToTrainAndTest(encodedData[AttSelection], 0.6, 'Churn')\n",
    "    PrintTrainTestInformation(x_train_feselection02,y_train_feselection02,x_test_feselection02,y_test_feselection02)\n",
    "    x_train = x_train_feselection02\n",
    "    y_train = y_train_feselection02\n",
    "    x_test  = x_test_feselection02\n",
    "    y_test = y_test_feselection02\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "RFModel = RandomForestLearning(x_train,y_train)\n",
    "end = time.time()\n",
    "RFAccuracy,RFPredictTest = RandomForestTesting(RFModel, x_test, y_test)\n",
    "print('Random Forest Accuracy: {:.3f}'.format(RFAccuracy))\n",
    "print('Time: ',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total night calls</th>\n",
       "      <th>Number vmail messages</th>\n",
       "      <th>Total intl charge</th>\n",
       "      <th>Total intl minutes</th>\n",
       "      <th>Total eve minutes</th>\n",
       "      <th>Total eve charge</th>\n",
       "      <th>Total intl calls</th>\n",
       "      <th>International plan</th>\n",
       "      <th>Customer service calls</th>\n",
       "      <th>Total day charge</th>\n",
       "      <th>Total day minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>9.4</td>\n",
       "      <td>199.4</td>\n",
       "      <td>16.95</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37.76</td>\n",
       "      <td>222.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>9.1</td>\n",
       "      <td>246.0</td>\n",
       "      <td>20.91</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17.44</td>\n",
       "      <td>102.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>12.7</td>\n",
       "      <td>107.9</td>\n",
       "      <td>9.17</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46.31</td>\n",
       "      <td>272.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>114</td>\n",
       "      <td>15</td>\n",
       "      <td>2.94</td>\n",
       "      <td>10.9</td>\n",
       "      <td>267.0</td>\n",
       "      <td>22.70</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.07</td>\n",
       "      <td>165.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>2.54</td>\n",
       "      <td>9.4</td>\n",
       "      <td>158.6</td>\n",
       "      <td>13.48</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36.50</td>\n",
       "      <td>214.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total night calls  Number vmail messages  Total intl charge  \\\n",
       "2360                107                      0               2.54   \n",
       "600                 140                      0               2.46   \n",
       "1501                 81                      0               3.43   \n",
       "1114                114                     15               2.94   \n",
       "517                 114                      0               2.54   \n",
       "\n",
       "      Total intl minutes  Total eve minutes  Total eve charge  \\\n",
       "2360                 9.4              199.4             16.95   \n",
       "600                  9.1              246.0             20.91   \n",
       "1501                12.7              107.9              9.17   \n",
       "1114                10.9              267.0             22.70   \n",
       "517                  9.4              158.6             13.48   \n",
       "\n",
       "      Total intl calls  International plan  Customer service calls  \\\n",
       "2360                 3                   0                       2   \n",
       "600                  4                   0                       2   \n",
       "1501                 2                   0                       0   \n",
       "1114                 4                   0                       1   \n",
       "517                  4                   0                       2   \n",
       "\n",
       "      Total day charge  Total day minutes  \n",
       "2360             37.76              222.1  \n",
       "600              17.44              102.6  \n",
       "1501             46.31              272.4  \n",
       "1114             28.07              165.1  \n",
       "517              36.50              214.7  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "featureSelection = []\n",
    "for name, item in feat_importances.iteritems():\n",
    "    if (item > 0.03):\n",
    "        featureSelection.append(name)\n",
    "featureTrainSelection = x_train[featureSelection]\n",
    "featureTestSelection = x_test[featureSelection]\n",
    "display(featureTrainSelection.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNLearning(DataTrain, TargetTrain):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    KNN = KNeighborsClassifier(n_neighbors=3)\n",
    "    KNN.fit(DataTrain, TargetTrain)\n",
    "    return KNN\n",
    "\n",
    "def KNNTesting(RFModel, DataTest, TargetTest):\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    PredictTestKNN = RFModel.predict(DataTest)\n",
    "    AccuracyKNN = accuracy_score(TargetTest, PredictTestKNN)\n",
    "    return AccuracyKNN, PredictTestKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8634658664666166\n",
      "Predict:  [False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "rfModel = KNNLearning(x_train, y_train)\n",
    "accuracy, predictTest = KNNTesting(rfModel, x_test, y_test)\n",
    "print('Accuracy: ', accuracy)\n",
    "print('Predict: ', predictTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\xuant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Import `Sequential` from `keras.models`\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Import `Dense` from `keras.layers`\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Dense(12, activation='relu', input_shape=(11,)))\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                144       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 257\n",
      "Trainable params: 257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.38289267,  0.1038509 ,  0.45557177,  0.04415339, -0.48689538,\n",
       "          0.42513138,  0.08291781,  0.37218356,  0.3609177 , -0.13142827,\n",
       "         -0.25899947, -0.50080544],\n",
       "        [-0.02342466, -0.00763321, -0.04668298,  0.3663292 , -0.26699293,\n",
       "         -0.27130866, -0.00607723,  0.2702278 ,  0.35820252,  0.19963783,\n",
       "         -0.3742559 ,  0.19571906],\n",
       "        [ 0.25894904,  0.26406986,  0.45465374, -0.36857003,  0.25091583,\n",
       "          0.23204654,  0.43381155, -0.23779461,  0.41992342,  0.4767384 ,\n",
       "         -0.26995018,  0.07601684],\n",
       "        [ 0.17224836,  0.27682304, -0.0299204 ,  0.23568124,  0.2225244 ,\n",
       "          0.20749402,  0.42920554,  0.14901364,  0.40105844,  0.00536996,\n",
       "          0.46754414, -0.3439737 ],\n",
       "        [ 0.41333097, -0.43051767, -0.27394313, -0.11671683,  0.03223932,\n",
       "          0.12114692,  0.41824096, -0.12707925, -0.49652156,  0.01699102,\n",
       "          0.50407344, -0.3412814 ],\n",
       "        [-0.16554925, -0.5102714 , -0.43046921,  0.15786439, -0.25161391,\n",
       "          0.23101121, -0.1797643 , -0.10491809, -0.44790798,  0.41161835,\n",
       "         -0.4018755 ,  0.23648626],\n",
       "        [-0.03562817, -0.00624317, -0.46987185, -0.38391542,  0.4905849 ,\n",
       "         -0.3796205 ,  0.36466295,  0.0762248 ,  0.31722814,  0.00104809,\n",
       "          0.16682541,  0.18307108],\n",
       "        [ 0.29411435,  0.07812595, -0.165086  ,  0.2718408 , -0.41317362,\n",
       "          0.4232242 ,  0.2991755 ,  0.04589266, -0.1063593 ,  0.37131774,\n",
       "         -0.0023647 , -0.32443857],\n",
       "        [-0.2328287 , -0.499906  ,  0.00488192, -0.23125163,  0.02671695,\n",
       "          0.48626107,  0.20208132, -0.06887519,  0.26554173,  0.4066466 ,\n",
       "         -0.04165497, -0.01094607],\n",
       "        [ 0.04557085, -0.02555302,  0.37781775,  0.36835474,  0.10468262,\n",
       "         -0.19988418, -0.47229344, -0.43685365, -0.06480029, -0.49613884,\n",
       "          0.33395505, -0.3507372 ],\n",
       "        [-0.4539539 ,  0.48879677, -0.05706438,  0.37171584, -0.02003559,\n",
       "         -0.23086536, -0.00778657,  0.4769721 ,  0.16181844,  0.13092667,\n",
       "         -0.25432265,  0.36068547]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 7.4170530e-02,  2.1154463e-02, -5.2467901e-01,  2.7366757e-02,\n",
       "          2.1860474e-01,  4.8828983e-01,  3.8990504e-01, -3.8300088e-01],\n",
       "        [-1.2454614e-01, -3.6139613e-01,  5.4142666e-01,  2.9763812e-01,\n",
       "         -4.9441427e-01,  1.4816165e-01, -1.6624272e-02,  3.5007161e-01],\n",
       "        [ 3.0080158e-01,  1.0134977e-01, -5.1074225e-01,  1.3814247e-01,\n",
       "          1.6503221e-01, -5.4138899e-04, -1.1612862e-01, -2.8051406e-01],\n",
       "        [-3.3806592e-01, -4.6237493e-01,  2.6094663e-01,  4.7396374e-01,\n",
       "          2.9969573e-01,  7.0925951e-02, -4.4932067e-02,  1.9497997e-01],\n",
       "        [ 6.6200674e-02, -2.6928067e-01,  2.5455332e-01, -2.4334580e-01,\n",
       "         -3.6364368e-01,  3.4151435e-02, -3.8286129e-01, -5.2242416e-01],\n",
       "        [-4.6866298e-02, -3.4792554e-01, -1.5770131e-01,  2.7675861e-01,\n",
       "          2.0399135e-01,  2.2130764e-01, -4.0127277e-01,  2.8502417e-01],\n",
       "        [-4.6350896e-02,  2.6321775e-01,  6.2416017e-02, -1.0349235e-01,\n",
       "          4.6282005e-01, -3.1785023e-01,  5.0711310e-01,  2.0313472e-01],\n",
       "        [-4.9296853e-01, -1.6105860e-01,  4.7109509e-01,  7.5558424e-02,\n",
       "         -5.1574922e-01,  2.9022455e-01,  8.5561395e-02, -7.1135819e-02],\n",
       "        [ 3.4121394e-02,  2.6173991e-01, -2.5863206e-01, -1.4414129e-01,\n",
       "          3.9552993e-01,  2.2654587e-01, -4.8229223e-01, -2.4953902e-01],\n",
       "        [-3.3866417e-01, -2.8252196e-01,  4.1827667e-01, -9.5258564e-02,\n",
       "          3.4912443e-01, -5.0746977e-02,  4.9551606e-02, -1.7533422e-02],\n",
       "        [-2.5333154e-01, -2.6855591e-01, -5.1531720e-01, -1.2025976e-01,\n",
       "          4.7179997e-01,  2.5548494e-01, -4.6003416e-01, -4.1796184e-01],\n",
       "        [-4.1415089e-01, -5.7478875e-02, -5.3991437e-02,  1.9083446e-01,\n",
       "          3.4372091e-01,  1.2382084e-01,  3.1852108e-01, -3.5561126e-01]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[-0.5613638 ],\n",
       "        [ 0.0633983 ],\n",
       "        [ 0.6984284 ],\n",
       "        [-0.695075  ],\n",
       "        [-0.49110153],\n",
       "        [-0.4579124 ],\n",
       "        [-0.63582605],\n",
       "        [ 0.38149798]], dtype=float32),\n",
       " array([0.], dtype=float32)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\xuant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "2000/2000 [==============================] - 2s 1ms/step - loss: 1.9607 - acc: 0.8265\n",
      "Epoch 2/500\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 1.1479 - acc: 0.8155\n",
      "Epoch 3/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.6152 - acc: 0.8350\n",
      "Epoch 4/500\n",
      "2000/2000 [==============================] - 1s 380us/step - loss: 0.4937 - acc: 0.8400\n",
      "Epoch 5/500\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.4764 - acc: 0.8420\n",
      "Epoch 6/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.4463 - acc: 0.8475\n",
      "Epoch 7/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.4196 - acc: 0.8475\n",
      "Epoch 8/500\n",
      "2000/2000 [==============================] - 1s 407us/step - loss: 0.4250 - acc: 0.8570\n",
      "Epoch 9/500\n",
      "2000/2000 [==============================] - 1s 406us/step - loss: 0.4221 - acc: 0.8480\n",
      "Epoch 10/500\n",
      "2000/2000 [==============================] - 1s 421us/step - loss: 0.3996 - acc: 0.8540\n",
      "Epoch 11/500\n",
      "2000/2000 [==============================] - 1s 486us/step - loss: 0.3940 - acc: 0.8585\n",
      "Epoch 12/500\n",
      "2000/2000 [==============================] - 1s 435us/step - loss: 0.3998 - acc: 0.8595\n",
      "Epoch 13/500\n",
      "2000/2000 [==============================] - 1s 421us/step - loss: 0.3814 - acc: 0.8655\n",
      "Epoch 14/500\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.3891 - acc: 0.8595\n",
      "Epoch 15/500\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.3774 - acc: 0.8600\n",
      "Epoch 16/500\n",
      "2000/2000 [==============================] - 1s 420us/step - loss: 0.3873 - acc: 0.8530\n",
      "Epoch 17/500\n",
      "2000/2000 [==============================] - 1s 402us/step - loss: 0.3729 - acc: 0.8675\n",
      "Epoch 18/500\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 0.3619 - acc: 0.8690\n",
      "Epoch 19/500\n",
      "2000/2000 [==============================] - 1s 396us/step - loss: 0.3672 - acc: 0.8640\n",
      "Epoch 20/500\n",
      "2000/2000 [==============================] - 1s 421us/step - loss: 0.3620 - acc: 0.8700\n",
      "Epoch 21/500\n",
      "2000/2000 [==============================] - 1s 409us/step - loss: 0.3666 - acc: 0.8655\n",
      "Epoch 22/500\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.3656 - acc: 0.8675\n",
      "Epoch 23/500\n",
      "2000/2000 [==============================] - 1s 429us/step - loss: 0.3529 - acc: 0.8700\n",
      "Epoch 24/500\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.3623 - acc: 0.8695\n",
      "Epoch 25/500\n",
      "2000/2000 [==============================] - 1s 415us/step - loss: 0.3482 - acc: 0.8755\n",
      "Epoch 26/500\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.3536 - acc: 0.8660\n",
      "Epoch 27/500\n",
      "2000/2000 [==============================] - 1s 413us/step - loss: 0.3454 - acc: 0.8690\n",
      "Epoch 28/500\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.3522 - acc: 0.8695\n",
      "Epoch 29/500\n",
      "2000/2000 [==============================] - 1s 414us/step - loss: 0.3784 - acc: 0.8580\n",
      "Epoch 30/500\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.3513 - acc: 0.8710\n",
      "Epoch 31/500\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.3480 - acc: 0.8670\n",
      "Epoch 32/500\n",
      "2000/2000 [==============================] - 1s 428us/step - loss: 0.3690 - acc: 0.8600\n",
      "Epoch 33/500\n",
      "2000/2000 [==============================] - 1s 418us/step - loss: 0.3478 - acc: 0.8650\n",
      "Epoch 34/500\n",
      "2000/2000 [==============================] - 1s 429us/step - loss: 0.3477 - acc: 0.8730\n",
      "Epoch 35/500\n",
      "2000/2000 [==============================] - 1s 467us/step - loss: 0.3535 - acc: 0.8695\n",
      "Epoch 36/500\n",
      "2000/2000 [==============================] - 1s 420us/step - loss: 0.3416 - acc: 0.8715\n",
      "Epoch 37/500\n",
      "2000/2000 [==============================] - 1s 409us/step - loss: 0.3312 - acc: 0.8770\n",
      "Epoch 38/500\n",
      "2000/2000 [==============================] - 1s 414us/step - loss: 0.3373 - acc: 0.8710\n",
      "Epoch 39/500\n",
      "2000/2000 [==============================] - 1s 402us/step - loss: 0.3401 - acc: 0.8750\n",
      "Epoch 40/500\n",
      "2000/2000 [==============================] - 1s 422us/step - loss: 0.3250 - acc: 0.8820\n",
      "Epoch 41/500\n",
      "2000/2000 [==============================] - 1s 415us/step - loss: 0.3335 - acc: 0.8725\n",
      "Epoch 42/500\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.3375 - acc: 0.8785\n",
      "Epoch 43/500\n",
      "2000/2000 [==============================] - 1s 404us/step - loss: 0.3470 - acc: 0.8730\n",
      "Epoch 44/500\n",
      "2000/2000 [==============================] - 1s 394us/step - loss: 0.3340 - acc: 0.8785\n",
      "Epoch 45/500\n",
      "2000/2000 [==============================] - 1s 402us/step - loss: 0.3314 - acc: 0.8730\n",
      "Epoch 46/500\n",
      "2000/2000 [==============================] - 1s 424us/step - loss: 0.3329 - acc: 0.8685\n",
      "Epoch 47/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.3398 - acc: 0.8710\n",
      "Epoch 48/500\n",
      "2000/2000 [==============================] - 1s 414us/step - loss: 0.3277 - acc: 0.8805\n",
      "Epoch 49/500\n",
      "2000/2000 [==============================] - 1s 473us/step - loss: 0.3284 - acc: 0.8725\n",
      "Epoch 50/500\n",
      "2000/2000 [==============================] - 1s 443us/step - loss: 0.3414 - acc: 0.8775\n",
      "Epoch 51/500\n",
      "2000/2000 [==============================] - 1s 413us/step - loss: 0.3339 - acc: 0.8735\n",
      "Epoch 52/500\n",
      "2000/2000 [==============================] - 1s 396us/step - loss: 0.3334 - acc: 0.8735\n",
      "Epoch 53/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.3331 - acc: 0.8810\n",
      "Epoch 54/500\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.3204 - acc: 0.8760\n",
      "Epoch 55/500\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.3246 - acc: 0.8835\n",
      "Epoch 56/500\n",
      "2000/2000 [==============================] - 1s 385us/step - loss: 0.3255 - acc: 0.8820\n",
      "Epoch 57/500\n",
      "2000/2000 [==============================] - 1s 412us/step - loss: 0.3214 - acc: 0.8895\n",
      "Epoch 58/500\n",
      "2000/2000 [==============================] - 1s 399us/step - loss: 0.3167 - acc: 0.8830\n",
      "Epoch 59/500\n",
      "2000/2000 [==============================] - 1s 399us/step - loss: 0.3239 - acc: 0.8740\n",
      "Epoch 60/500\n",
      "2000/2000 [==============================] - 1s 398us/step - loss: 0.3195 - acc: 0.8890\n",
      "Epoch 61/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.3211 - acc: 0.8805\n",
      "Epoch 62/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.3359 - acc: 0.8785\n",
      "Epoch 63/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.3180 - acc: 0.8840\n",
      "Epoch 64/500\n",
      "2000/2000 [==============================] - 1s 406us/step - loss: 0.3166 - acc: 0.8845\n",
      "Epoch 65/500\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.3182 - acc: 0.8840 0s - loss: 0.3145\n",
      "Epoch 66/500\n",
      "2000/2000 [==============================] - 1s 399us/step - loss: 0.3238 - acc: 0.8765\n",
      "Epoch 67/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.3279 - acc: 0.8780\n",
      "Epoch 68/500\n",
      "2000/2000 [==============================] - 1s 389us/step - loss: 0.3156 - acc: 0.8835\n",
      "Epoch 69/500\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.3130 - acc: 0.8825\n",
      "Epoch 70/500\n",
      "2000/2000 [==============================] - 1s 457us/step - loss: 0.3172 - acc: 0.8815\n",
      "Epoch 71/500\n",
      "2000/2000 [==============================] - 1s 424us/step - loss: 0.3134 - acc: 0.8855\n",
      "Epoch 72/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.3218 - acc: 0.8830\n",
      "Epoch 73/500\n",
      "2000/2000 [==============================] - 1s 407us/step - loss: 0.3166 - acc: 0.8785\n",
      "Epoch 74/500\n",
      "2000/2000 [==============================] - 1s 422us/step - loss: 0.3194 - acc: 0.8840\n",
      "Epoch 75/500\n",
      "2000/2000 [==============================] - 1s 479us/step - loss: 0.3083 - acc: 0.8855\n",
      "Epoch 76/500\n",
      "2000/2000 [==============================] - 1s 437us/step - loss: 0.3209 - acc: 0.8845\n",
      "Epoch 77/500\n",
      "2000/2000 [==============================] - 1s 395us/step - loss: 0.3132 - acc: 0.8830\n",
      "Epoch 78/500\n",
      "2000/2000 [==============================] - 1s 460us/step - loss: 0.3257 - acc: 0.8775\n",
      "Epoch 79/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 382us/step - loss: 0.3155 - acc: 0.8845\n",
      "Epoch 80/500\n",
      "2000/2000 [==============================] - 1s 446us/step - loss: 0.3098 - acc: 0.8830\n",
      "Epoch 81/500\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 0.3163 - acc: 0.8850\n",
      "Epoch 82/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.3156 - acc: 0.8800\n",
      "Epoch 83/500\n",
      "2000/2000 [==============================] - 1s 489us/step - loss: 0.3079 - acc: 0.8855\n",
      "Epoch 84/500\n",
      "2000/2000 [==============================] - 1s 475us/step - loss: 0.3262 - acc: 0.8745\n",
      "Epoch 85/500\n",
      "2000/2000 [==============================] - 1s 443us/step - loss: 0.3194 - acc: 0.8795\n",
      "Epoch 86/500\n",
      "2000/2000 [==============================] - 1s 418us/step - loss: 0.3133 - acc: 0.8860\n",
      "Epoch 87/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.3038 - acc: 0.8860\n",
      "Epoch 88/500\n",
      "2000/2000 [==============================] - 1s 455us/step - loss: 0.3222 - acc: 0.8870\n",
      "Epoch 89/500\n",
      "2000/2000 [==============================] - 1s 398us/step - loss: 0.3128 - acc: 0.8830\n",
      "Epoch 90/500\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.3101 - acc: 0.8885\n",
      "Epoch 91/500\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.3074 - acc: 0.8930\n",
      "Epoch 92/500\n",
      "2000/2000 [==============================] - 1s 493us/step - loss: 0.3043 - acc: 0.8830\n",
      "Epoch 93/500\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 0.3177 - acc: 0.8825\n",
      "Epoch 94/500\n",
      "2000/2000 [==============================] - 1s 382us/step - loss: 0.3058 - acc: 0.8835\n",
      "Epoch 95/500\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 0.3005 - acc: 0.8875\n",
      "Epoch 96/500\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 0.3196 - acc: 0.8810\n",
      "Epoch 97/500\n",
      "2000/2000 [==============================] - 1s 375us/step - loss: 0.3116 - acc: 0.8760\n",
      "Epoch 98/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.3056 - acc: 0.8875\n",
      "Epoch 99/500\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.3121 - acc: 0.8835\n",
      "Epoch 100/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.3090 - acc: 0.8840\n",
      "Epoch 101/500\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.3088 - acc: 0.8865\n",
      "Epoch 102/500\n",
      "2000/2000 [==============================] - 1s 412us/step - loss: 0.3166 - acc: 0.8820\n",
      "Epoch 103/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.3004 - acc: 0.8855\n",
      "Epoch 104/500\n",
      "2000/2000 [==============================] - 1s 404us/step - loss: 0.3063 - acc: 0.8855\n",
      "Epoch 105/500\n",
      "2000/2000 [==============================] - 1s 371us/step - loss: 0.3012 - acc: 0.8880\n",
      "Epoch 106/500\n",
      "2000/2000 [==============================] - 1s 409us/step - loss: 0.3010 - acc: 0.8890\n",
      "Epoch 107/500\n",
      "2000/2000 [==============================] - 1s 417us/step - loss: 0.3082 - acc: 0.8875\n",
      "Epoch 108/500\n",
      "2000/2000 [==============================] - 1s 463us/step - loss: 0.3142 - acc: 0.8850\n",
      "Epoch 109/500\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.2968 - acc: 0.8895\n",
      "Epoch 110/500\n",
      "2000/2000 [==============================] - 1s 413us/step - loss: 0.3067 - acc: 0.8825\n",
      "Epoch 111/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.3020 - acc: 0.8870\n",
      "Epoch 112/500\n",
      "2000/2000 [==============================] - 1s 487us/step - loss: 0.3023 - acc: 0.8885\n",
      "Epoch 113/500\n",
      "2000/2000 [==============================] - 1s 418us/step - loss: 0.3179 - acc: 0.8820\n",
      "Epoch 114/500\n",
      "2000/2000 [==============================] - 1s 422us/step - loss: 0.2997 - acc: 0.8910\n",
      "Epoch 115/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.3072 - acc: 0.8880\n",
      "Epoch 116/500\n",
      "2000/2000 [==============================] - 1s 422us/step - loss: 0.3091 - acc: 0.8835\n",
      "Epoch 117/500\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.3096 - acc: 0.8840\n",
      "Epoch 118/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.3082 - acc: 0.8890\n",
      "Epoch 119/500\n",
      "2000/2000 [==============================] - 1s 430us/step - loss: 0.3115 - acc: 0.8860\n",
      "Epoch 120/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.3010 - acc: 0.8915\n",
      "Epoch 121/500\n",
      "2000/2000 [==============================] - 1s 433us/step - loss: 0.3012 - acc: 0.8855\n",
      "Epoch 122/500\n",
      "2000/2000 [==============================] - 1s 424us/step - loss: 0.3076 - acc: 0.8835\n",
      "Epoch 123/500\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.3043 - acc: 0.8925\n",
      "Epoch 124/500\n",
      "2000/2000 [==============================] - 1s 434us/step - loss: 0.2974 - acc: 0.8915\n",
      "Epoch 125/500\n",
      "2000/2000 [==============================] - 1s 407us/step - loss: 0.2997 - acc: 0.8875\n",
      "Epoch 126/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2948 - acc: 0.8855\n",
      "Epoch 127/500\n",
      "2000/2000 [==============================] - 1s 464us/step - loss: 0.3090 - acc: 0.8825\n",
      "Epoch 128/500\n",
      "2000/2000 [==============================] - 1s 421us/step - loss: 0.3013 - acc: 0.8900\n",
      "Epoch 129/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.3053 - acc: 0.8860\n",
      "Epoch 130/500\n",
      "2000/2000 [==============================] - 1s 397us/step - loss: 0.3041 - acc: 0.8840\n",
      "Epoch 131/500\n",
      "2000/2000 [==============================] - 1s 432us/step - loss: 0.3188 - acc: 0.8805\n",
      "Epoch 132/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.2988 - acc: 0.8885\n",
      "Epoch 133/500\n",
      "2000/2000 [==============================] - 1s 424us/step - loss: 0.3010 - acc: 0.8920\n",
      "Epoch 134/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.2994 - acc: 0.8875\n",
      "Epoch 135/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.2973 - acc: 0.8875\n",
      "Epoch 136/500\n",
      "2000/2000 [==============================] - 1s 410us/step - loss: 0.2934 - acc: 0.8930\n",
      "Epoch 137/500\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.2962 - acc: 0.8885\n",
      "Epoch 138/500\n",
      "2000/2000 [==============================] - 1s 399us/step - loss: 0.2920 - acc: 0.8870\n",
      "Epoch 139/500\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.2991 - acc: 0.8895\n",
      "Epoch 140/500\n",
      "2000/2000 [==============================] - 1s 415us/step - loss: 0.2970 - acc: 0.8865\n",
      "Epoch 141/500\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.2973 - acc: 0.8845\n",
      "Epoch 142/500\n",
      "2000/2000 [==============================] - 1s 459us/step - loss: 0.2975 - acc: 0.8890\n",
      "Epoch 143/500\n",
      "2000/2000 [==============================] - 1s 492us/step - loss: 0.2954 - acc: 0.8945\n",
      "Epoch 144/500\n",
      "2000/2000 [==============================] - 1s 487us/step - loss: 0.2947 - acc: 0.8890\n",
      "Epoch 145/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2951 - acc: 0.8880\n",
      "Epoch 146/500\n",
      "2000/2000 [==============================] - 1s 479us/step - loss: 0.2972 - acc: 0.8875\n",
      "Epoch 147/500\n",
      "2000/2000 [==============================] - 1s 404us/step - loss: 0.2937 - acc: 0.8915\n",
      "Epoch 148/500\n",
      "2000/2000 [==============================] - 1s 415us/step - loss: 0.2992 - acc: 0.8895\n",
      "Epoch 149/500\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 0.2920 - acc: 0.8925\n",
      "Epoch 150/500\n",
      "2000/2000 [==============================] - 1s 458us/step - loss: 0.2930 - acc: 0.8980\n",
      "Epoch 151/500\n",
      "2000/2000 [==============================] - 1s 438us/step - loss: 0.2914 - acc: 0.8910\n",
      "Epoch 152/500\n",
      "2000/2000 [==============================] - 1s 380us/step - loss: 0.2932 - acc: 0.8930\n",
      "Epoch 153/500\n",
      "2000/2000 [==============================] - 1s 415us/step - loss: 0.2973 - acc: 0.8915\n",
      "Epoch 154/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2955 - acc: 0.8865\n",
      "Epoch 155/500\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.2913 - acc: 0.8875\n",
      "Epoch 156/500\n",
      "2000/2000 [==============================] - 1s 501us/step - loss: 0.2882 - acc: 0.8890\n",
      "Epoch 157/500\n",
      "2000/2000 [==============================] - 1s 444us/step - loss: 0.2887 - acc: 0.8910\n",
      "Epoch 158/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2888 - acc: 0.8970\n",
      "Epoch 159/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 412us/step - loss: 0.2916 - acc: 0.8920\n",
      "Epoch 160/500\n",
      "2000/2000 [==============================] - 1s 422us/step - loss: 0.2901 - acc: 0.8900\n",
      "Epoch 161/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.3023 - acc: 0.8880\n",
      "Epoch 162/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2989 - acc: 0.8905\n",
      "Epoch 163/500\n",
      "2000/2000 [==============================] - 1s 363us/step - loss: 0.2934 - acc: 0.8910\n",
      "Epoch 164/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2920 - acc: 0.8940\n",
      "Epoch 165/500\n",
      "2000/2000 [==============================] - 1s 477us/step - loss: 0.2905 - acc: 0.8930\n",
      "Epoch 166/500\n",
      "2000/2000 [==============================] - 1s 396us/step - loss: 0.2865 - acc: 0.8930\n",
      "Epoch 167/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2917 - acc: 0.8930\n",
      "Epoch 168/500\n",
      "2000/2000 [==============================] - 1s 368us/step - loss: 0.2935 - acc: 0.8905\n",
      "Epoch 169/500\n",
      "2000/2000 [==============================] - 1s 359us/step - loss: 0.2937 - acc: 0.8940\n",
      "Epoch 170/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.2910 - acc: 0.8915\n",
      "Epoch 171/500\n",
      "2000/2000 [==============================] - 1s 434us/step - loss: 0.2905 - acc: 0.8915\n",
      "Epoch 172/500\n",
      "2000/2000 [==============================] - 1s 435us/step - loss: 0.2957 - acc: 0.8840\n",
      "Epoch 173/500\n",
      "2000/2000 [==============================] - 1s 495us/step - loss: 0.2904 - acc: 0.8930\n",
      "Epoch 174/500\n",
      "2000/2000 [==============================] - 1s 479us/step - loss: 0.2890 - acc: 0.8910\n",
      "Epoch 175/500\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.2958 - acc: 0.8880\n",
      "Epoch 176/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2887 - acc: 0.8930\n",
      "Epoch 177/500\n",
      "2000/2000 [==============================] - 1s 382us/step - loss: 0.2874 - acc: 0.8960\n",
      "Epoch 178/500\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 0.2940 - acc: 0.8895\n",
      "Epoch 179/500\n",
      "2000/2000 [==============================] - 1s 372us/step - loss: 0.2900 - acc: 0.8870\n",
      "Epoch 180/500\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 0.2839 - acc: 0.8910\n",
      "Epoch 181/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.2863 - acc: 0.8885\n",
      "Epoch 182/500\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 0.2913 - acc: 0.8890\n",
      "Epoch 183/500\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 0.2901 - acc: 0.8930\n",
      "Epoch 184/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2894 - acc: 0.8940\n",
      "Epoch 185/500\n",
      "2000/2000 [==============================] - 1s 426us/step - loss: 0.2911 - acc: 0.8900\n",
      "Epoch 186/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2851 - acc: 0.8935\n",
      "Epoch 187/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2874 - acc: 0.8875\n",
      "Epoch 188/500\n",
      "2000/2000 [==============================] - 1s 360us/step - loss: 0.2842 - acc: 0.8975\n",
      "Epoch 189/500\n",
      "2000/2000 [==============================] - 1s 372us/step - loss: 0.2951 - acc: 0.8900\n",
      "Epoch 190/500\n",
      "2000/2000 [==============================] - 1s 368us/step - loss: 0.2871 - acc: 0.8945\n",
      "Epoch 191/500\n",
      "2000/2000 [==============================] - 1s 371us/step - loss: 0.2842 - acc: 0.8950\n",
      "Epoch 192/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2864 - acc: 0.8905\n",
      "Epoch 193/500\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 0.2802 - acc: 0.8935\n",
      "Epoch 194/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2789 - acc: 0.8930\n",
      "Epoch 195/500\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 0.2846 - acc: 0.8970\n",
      "Epoch 196/500\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 0.2810 - acc: 0.8910\n",
      "Epoch 197/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2820 - acc: 0.9000\n",
      "Epoch 198/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2794 - acc: 0.8920\n",
      "Epoch 199/500\n",
      "2000/2000 [==============================] - 1s 396us/step - loss: 0.2822 - acc: 0.8930\n",
      "Epoch 200/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2816 - acc: 0.8965\n",
      "Epoch 201/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2832 - acc: 0.8915\n",
      "Epoch 202/500\n",
      "2000/2000 [==============================] - 1s 390us/step - loss: 0.2828 - acc: 0.8965\n",
      "Epoch 203/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2865 - acc: 0.8910\n",
      "Epoch 204/500\n",
      "2000/2000 [==============================] - 1s 380us/step - loss: 0.2819 - acc: 0.8920\n",
      "Epoch 205/500\n",
      "2000/2000 [==============================] - 1s 402us/step - loss: 0.2830 - acc: 0.8935\n",
      "Epoch 206/500\n",
      "2000/2000 [==============================] - 1s 423us/step - loss: 0.2785 - acc: 0.8900\n",
      "Epoch 207/500\n",
      "2000/2000 [==============================] - 1s 385us/step - loss: 0.2749 - acc: 0.8965\n",
      "Epoch 208/500\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.2905 - acc: 0.8950\n",
      "Epoch 209/500\n",
      "2000/2000 [==============================] - 1s 375us/step - loss: 0.2805 - acc: 0.8915\n",
      "Epoch 210/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2844 - acc: 0.8915\n",
      "Epoch 211/500\n",
      "2000/2000 [==============================] - 1s 380us/step - loss: 0.2772 - acc: 0.8965\n",
      "Epoch 212/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2758 - acc: 0.8950\n",
      "Epoch 213/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2761 - acc: 0.8975\n",
      "Epoch 214/500\n",
      "2000/2000 [==============================] - 1s 367us/step - loss: 0.2768 - acc: 0.8945\n",
      "Epoch 215/500\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.2747 - acc: 0.8995\n",
      "Epoch 216/500\n",
      "2000/2000 [==============================] - 1s 367us/step - loss: 0.2755 - acc: 0.8995\n",
      "Epoch 217/500\n",
      "2000/2000 [==============================] - 1s 368us/step - loss: 0.2888 - acc: 0.8925\n",
      "Epoch 218/500\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 0.2766 - acc: 0.8960\n",
      "Epoch 219/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2825 - acc: 0.8895\n",
      "Epoch 220/500\n",
      "2000/2000 [==============================] - 1s 372us/step - loss: 0.2795 - acc: 0.8945\n",
      "Epoch 221/500\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 0.2744 - acc: 0.8955\n",
      "Epoch 222/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2751 - acc: 0.8995\n",
      "Epoch 223/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.2751 - acc: 0.8960\n",
      "Epoch 224/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2766 - acc: 0.8975\n",
      "Epoch 225/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2749 - acc: 0.8930\n",
      "Epoch 226/500\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.2750 - acc: 0.8980\n",
      "Epoch 227/500\n",
      "2000/2000 [==============================] - 1s 428us/step - loss: 0.2745 - acc: 0.8965\n",
      "Epoch 228/500\n",
      "2000/2000 [==============================] - 1s 390us/step - loss: 0.2757 - acc: 0.8990\n",
      "Epoch 229/500\n",
      "2000/2000 [==============================] - 1s 385us/step - loss: 0.2798 - acc: 0.8905\n",
      "Epoch 230/500\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 0.2807 - acc: 0.8955\n",
      "Epoch 231/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2746 - acc: 0.8980\n",
      "Epoch 232/500\n",
      "2000/2000 [==============================] - 1s 389us/step - loss: 0.2689 - acc: 0.9015\n",
      "Epoch 233/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2715 - acc: 0.8945\n",
      "Epoch 234/500\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.2746 - acc: 0.8990\n",
      "Epoch 235/500\n",
      "2000/2000 [==============================] - 1s 382us/step - loss: 0.2831 - acc: 0.8895\n",
      "Epoch 236/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2759 - acc: 0.8970\n",
      "Epoch 237/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2780 - acc: 0.8990\n",
      "Epoch 238/500\n",
      "2000/2000 [==============================] - 1s 394us/step - loss: 0.2764 - acc: 0.8965\n",
      "Epoch 239/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 368us/step - loss: 0.2737 - acc: 0.8905\n",
      "Epoch 240/500\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.2735 - acc: 0.8925\n",
      "Epoch 241/500\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.2708 - acc: 0.8955\n",
      "Epoch 242/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2719 - acc: 0.8955\n",
      "Epoch 243/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.2856 - acc: 0.8910\n",
      "Epoch 244/500\n",
      "2000/2000 [==============================] - 1s 360us/step - loss: 0.2762 - acc: 0.8990\n",
      "Epoch 245/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2731 - acc: 0.9010\n",
      "Epoch 246/500\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.2693 - acc: 0.8950\n",
      "Epoch 247/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2717 - acc: 0.8960\n",
      "Epoch 248/500\n",
      "2000/2000 [==============================] - 1s 436us/step - loss: 0.2765 - acc: 0.8985\n",
      "Epoch 249/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2699 - acc: 0.9000\n",
      "Epoch 250/500\n",
      "2000/2000 [==============================] - 1s 375us/step - loss: 0.2745 - acc: 0.8970\n",
      "Epoch 251/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2706 - acc: 0.9000\n",
      "Epoch 252/500\n",
      "2000/2000 [==============================] - 1s 359us/step - loss: 0.2699 - acc: 0.9015\n",
      "Epoch 253/500\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.2799 - acc: 0.8960\n",
      "Epoch 254/500\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 0.2680 - acc: 0.8980\n",
      "Epoch 255/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2775 - acc: 0.8955\n",
      "Epoch 256/500\n",
      "2000/2000 [==============================] - 1s 362us/step - loss: 0.2750 - acc: 0.8920\n",
      "Epoch 257/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2757 - acc: 0.8965\n",
      "Epoch 258/500\n",
      "2000/2000 [==============================] - 1s 375us/step - loss: 0.2711 - acc: 0.8970\n",
      "Epoch 259/500\n",
      "2000/2000 [==============================] - 1s 358us/step - loss: 0.2694 - acc: 0.9040\n",
      "Epoch 260/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.2747 - acc: 0.8975\n",
      "Epoch 261/500\n",
      "2000/2000 [==============================] - 1s 371us/step - loss: 0.2678 - acc: 0.8980\n",
      "Epoch 262/500\n",
      "2000/2000 [==============================] - 1s 371us/step - loss: 0.2753 - acc: 0.8995\n",
      "Epoch 263/500\n",
      "2000/2000 [==============================] - 1s 360us/step - loss: 0.2716 - acc: 0.8955\n",
      "Epoch 264/500\n",
      "2000/2000 [==============================] - 1s 382us/step - loss: 0.2706 - acc: 0.8975\n",
      "Epoch 265/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.2705 - acc: 0.9000\n",
      "Epoch 266/500\n",
      "2000/2000 [==============================] - 1s 367us/step - loss: 0.2757 - acc: 0.8975\n",
      "Epoch 267/500\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.2717 - acc: 0.8995\n",
      "Epoch 268/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2749 - acc: 0.8905\n",
      "Epoch 269/500\n",
      "2000/2000 [==============================] - 1s 438us/step - loss: 0.2740 - acc: 0.9005\n",
      "Epoch 270/500\n",
      "2000/2000 [==============================] - 1s 406us/step - loss: 0.2687 - acc: 0.9020\n",
      "Epoch 271/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2864 - acc: 0.8945\n",
      "Epoch 272/500\n",
      "2000/2000 [==============================] - 1s 380us/step - loss: 0.2764 - acc: 0.8955\n",
      "Epoch 273/500\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 0.2704 - acc: 0.8990 0s - loss: 0.2853 -\n",
      "Epoch 274/500\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.2748 - acc: 0.8960\n",
      "Epoch 275/500\n",
      "2000/2000 [==============================] - 1s 385us/step - loss: 0.2771 - acc: 0.8965\n",
      "Epoch 276/500\n",
      "2000/2000 [==============================] - 1s 397us/step - loss: 0.2686 - acc: 0.9030\n",
      "Epoch 277/500\n",
      "2000/2000 [==============================] - 1s 390us/step - loss: 0.2716 - acc: 0.8965\n",
      "Epoch 278/500\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.2661 - acc: 0.8970\n",
      "Epoch 279/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.2678 - acc: 0.9025\n",
      "Epoch 280/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2660 - acc: 0.9035\n",
      "Epoch 281/500\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 0.2741 - acc: 0.8965\n",
      "Epoch 282/500\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 0.2677 - acc: 0.9025\n",
      "Epoch 283/500\n",
      "2000/2000 [==============================] - 1s 382us/step - loss: 0.2665 - acc: 0.9045\n",
      "Epoch 284/500\n",
      "2000/2000 [==============================] - 1s 410us/step - loss: 0.2708 - acc: 0.9015\n",
      "Epoch 285/500\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.2716 - acc: 0.8970\n",
      "Epoch 286/500\n",
      "2000/2000 [==============================] - 1s 417us/step - loss: 0.2715 - acc: 0.8970\n",
      "Epoch 287/500\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 0.2683 - acc: 0.8995\n",
      "Epoch 288/500\n",
      "2000/2000 [==============================] - 1s 362us/step - loss: 0.2746 - acc: 0.8955\n",
      "Epoch 289/500\n",
      "2000/2000 [==============================] - 1s 435us/step - loss: 0.2651 - acc: 0.9030\n",
      "Epoch 290/500\n",
      "2000/2000 [==============================] - 1s 449us/step - loss: 0.2688 - acc: 0.9040\n",
      "Epoch 291/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2707 - acc: 0.8970\n",
      "Epoch 292/500\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.2722 - acc: 0.8915\n",
      "Epoch 293/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.2702 - acc: 0.9015\n",
      "Epoch 294/500\n",
      "2000/2000 [==============================] - 1s 404us/step - loss: 0.2642 - acc: 0.9030\n",
      "Epoch 295/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2641 - acc: 0.8960\n",
      "Epoch 296/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2642 - acc: 0.8970\n",
      "Epoch 297/500\n",
      "2000/2000 [==============================] - 1s 389us/step - loss: 0.2702 - acc: 0.8990\n",
      "Epoch 298/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2774 - acc: 0.8940\n",
      "Epoch 299/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2676 - acc: 0.9015\n",
      "Epoch 300/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2667 - acc: 0.8995\n",
      "Epoch 301/500\n",
      "2000/2000 [==============================] - 1s 371us/step - loss: 0.2765 - acc: 0.9000\n",
      "Epoch 302/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.2690 - acc: 0.9025\n",
      "Epoch 303/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2677 - acc: 0.9020\n",
      "Epoch 304/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2604 - acc: 0.9050\n",
      "Epoch 305/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2683 - acc: 0.9015 0s - loss: 0.2981 \n",
      "Epoch 306/500\n",
      "2000/2000 [==============================] - 1s 397us/step - loss: 0.2659 - acc: 0.8980\n",
      "Epoch 307/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2685 - acc: 0.8950\n",
      "Epoch 308/500\n",
      "2000/2000 [==============================] - 1s 389us/step - loss: 0.2688 - acc: 0.9000\n",
      "Epoch 309/500\n",
      "2000/2000 [==============================] - 1s 420us/step - loss: 0.2692 - acc: 0.8985\n",
      "Epoch 310/500\n",
      "2000/2000 [==============================] - 1s 438us/step - loss: 0.2631 - acc: 0.9055\n",
      "Epoch 311/500\n",
      "2000/2000 [==============================] - 1s 413us/step - loss: 0.2564 - acc: 0.9045\n",
      "Epoch 312/500\n",
      "2000/2000 [==============================] - 1s 395us/step - loss: 0.2602 - acc: 0.9010\n",
      "Epoch 313/500\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 0.2615 - acc: 0.9015\n",
      "Epoch 314/500\n",
      "2000/2000 [==============================] - 1s 394us/step - loss: 0.2655 - acc: 0.9030\n",
      "Epoch 315/500\n",
      "2000/2000 [==============================] - 1s 404us/step - loss: 0.2604 - acc: 0.9080\n",
      "Epoch 316/500\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.2575 - acc: 0.9040\n",
      "Epoch 317/500\n",
      "2000/2000 [==============================] - 1s 404us/step - loss: 0.2611 - acc: 0.9025\n",
      "Epoch 318/500\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.2617 - acc: 0.9015\n",
      "Epoch 319/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 395us/step - loss: 0.2630 - acc: 0.9060\n",
      "Epoch 320/500\n",
      "2000/2000 [==============================] - 1s 365us/step - loss: 0.2575 - acc: 0.9025\n",
      "Epoch 321/500\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 0.2630 - acc: 0.9030\n",
      "Epoch 322/500\n",
      "2000/2000 [==============================] - 1s 389us/step - loss: 0.2588 - acc: 0.9030\n",
      "Epoch 323/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2588 - acc: 0.9005\n",
      "Epoch 324/500\n",
      "2000/2000 [==============================] - 1s 394us/step - loss: 0.2730 - acc: 0.8910\n",
      "Epoch 325/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2596 - acc: 0.9075\n",
      "Epoch 326/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2600 - acc: 0.9060\n",
      "Epoch 327/500\n",
      "2000/2000 [==============================] - 1s 380us/step - loss: 0.2541 - acc: 0.9035\n",
      "Epoch 328/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2541 - acc: 0.9045\n",
      "Epoch 329/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2599 - acc: 0.9020\n",
      "Epoch 330/500\n",
      "2000/2000 [==============================] - 1s 454us/step - loss: 0.2567 - acc: 0.9085\n",
      "Epoch 331/500\n",
      "2000/2000 [==============================] - 1s 513us/step - loss: 0.2639 - acc: 0.9050\n",
      "Epoch 332/500\n",
      "2000/2000 [==============================] - 1s 385us/step - loss: 0.2618 - acc: 0.8955\n",
      "Epoch 333/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2641 - acc: 0.9070\n",
      "Epoch 334/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2588 - acc: 0.9005\n",
      "Epoch 335/500\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 0.2633 - acc: 0.9010\n",
      "Epoch 336/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.2542 - acc: 0.9065 0s - loss: 0.2717 \n",
      "Epoch 337/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2544 - acc: 0.9040\n",
      "Epoch 338/500\n",
      "2000/2000 [==============================] - 1s 423us/step - loss: 0.2608 - acc: 0.9055\n",
      "Epoch 339/500\n",
      "2000/2000 [==============================] - 1s 438us/step - loss: 0.2623 - acc: 0.9035\n",
      "Epoch 340/500\n",
      "2000/2000 [==============================] - 1s 439us/step - loss: 0.2608 - acc: 0.9020\n",
      "Epoch 341/500\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.2568 - acc: 0.9085\n",
      "Epoch 342/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.2569 - acc: 0.9070\n",
      "Epoch 343/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.2577 - acc: 0.9060\n",
      "Epoch 344/500\n",
      "2000/2000 [==============================] - 1s 398us/step - loss: 0.2597 - acc: 0.9080\n",
      "Epoch 345/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2568 - acc: 0.9075\n",
      "Epoch 346/500\n",
      "2000/2000 [==============================] - 1s 394us/step - loss: 0.2503 - acc: 0.9020\n",
      "Epoch 347/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2592 - acc: 0.9020\n",
      "Epoch 348/500\n",
      "2000/2000 [==============================] - 1s 468us/step - loss: 0.2611 - acc: 0.8985\n",
      "Epoch 349/500\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 0.2673 - acc: 0.9055\n",
      "Epoch 350/500\n",
      "2000/2000 [==============================] - 1s 425us/step - loss: 0.2559 - acc: 0.9015\n",
      "Epoch 351/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2596 - acc: 0.9005\n",
      "Epoch 352/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2560 - acc: 0.9045\n",
      "Epoch 353/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2636 - acc: 0.9010\n",
      "Epoch 354/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.2575 - acc: 0.9020\n",
      "Epoch 355/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2505 - acc: 0.9065\n",
      "Epoch 356/500\n",
      "2000/2000 [==============================] - 1s 398us/step - loss: 0.2500 - acc: 0.9110\n",
      "Epoch 357/500\n",
      "2000/2000 [==============================] - 1s 405us/step - loss: 0.2543 - acc: 0.9055\n",
      "Epoch 358/500\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 0.2593 - acc: 0.9050\n",
      "Epoch 359/500\n",
      "2000/2000 [==============================] - 1s 420us/step - loss: 0.2624 - acc: 0.9030\n",
      "Epoch 360/500\n",
      "2000/2000 [==============================] - 1s 442us/step - loss: 0.2502 - acc: 0.9045\n",
      "Epoch 361/500\n",
      "2000/2000 [==============================] - 1s 389us/step - loss: 0.2505 - acc: 0.9065\n",
      "Epoch 362/500\n",
      "2000/2000 [==============================] - 1s 375us/step - loss: 0.2561 - acc: 0.9020\n",
      "Epoch 363/500\n",
      "2000/2000 [==============================] - 1s 396us/step - loss: 0.2511 - acc: 0.9070\n",
      "Epoch 364/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2532 - acc: 0.9030\n",
      "Epoch 365/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2515 - acc: 0.9085\n",
      "Epoch 366/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2519 - acc: 0.9055\n",
      "Epoch 367/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.2536 - acc: 0.9055\n",
      "Epoch 368/500\n",
      "2000/2000 [==============================] - 1s 390us/step - loss: 0.2490 - acc: 0.9065\n",
      "Epoch 369/500\n",
      "2000/2000 [==============================] - 1s 460us/step - loss: 0.2579 - acc: 0.9060\n",
      "Epoch 370/500\n",
      "2000/2000 [==============================] - 1s 445us/step - loss: 0.2535 - acc: 0.9055\n",
      "Epoch 371/500\n",
      "2000/2000 [==============================] - 1s 400us/step - loss: 0.2520 - acc: 0.9010\n",
      "Epoch 372/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2527 - acc: 0.9090\n",
      "Epoch 373/500\n",
      "2000/2000 [==============================] - 1s 397us/step - loss: 0.2541 - acc: 0.9050\n",
      "Epoch 374/500\n",
      "2000/2000 [==============================] - 1s 385us/step - loss: 0.2561 - acc: 0.9060\n",
      "Epoch 375/500\n",
      "2000/2000 [==============================] - 1s 394us/step - loss: 0.2550 - acc: 0.9055\n",
      "Epoch 376/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2536 - acc: 0.9055\n",
      "Epoch 377/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2586 - acc: 0.9035\n",
      "Epoch 378/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2542 - acc: 0.9060\n",
      "Epoch 379/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2513 - acc: 0.9100\n",
      "Epoch 380/500\n",
      "2000/2000 [==============================] - 1s 399us/step - loss: 0.2510 - acc: 0.9105\n",
      "Epoch 381/500\n",
      "2000/2000 [==============================] - 1s 385us/step - loss: 0.2587 - acc: 0.9035\n",
      "Epoch 382/500\n",
      "2000/2000 [==============================] - 1s 399us/step - loss: 0.2541 - acc: 0.9065\n",
      "Epoch 383/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2512 - acc: 0.9065\n",
      "Epoch 384/500\n",
      "2000/2000 [==============================] - 1s 409us/step - loss: 0.2508 - acc: 0.9005\n",
      "Epoch 385/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2537 - acc: 0.9050\n",
      "Epoch 386/500\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 0.2514 - acc: 0.9045\n",
      "Epoch 387/500\n",
      "2000/2000 [==============================] - 1s 392us/step - loss: 0.2552 - acc: 0.9025\n",
      "Epoch 388/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2529 - acc: 0.9085\n",
      "Epoch 389/500\n",
      "2000/2000 [==============================] - 1s 438us/step - loss: 0.2507 - acc: 0.9055\n",
      "Epoch 390/500\n",
      "2000/2000 [==============================] - 1s 453us/step - loss: 0.2584 - acc: 0.9030\n",
      "Epoch 391/500\n",
      "2000/2000 [==============================] - 1s 393us/step - loss: 0.2503 - acc: 0.9070\n",
      "Epoch 392/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2538 - acc: 0.9030\n",
      "Epoch 393/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2465 - acc: 0.9100\n",
      "Epoch 394/500\n",
      "2000/2000 [==============================] - 1s 397us/step - loss: 0.2550 - acc: 0.9050\n",
      "Epoch 395/500\n",
      "2000/2000 [==============================] - 1s 398us/step - loss: 0.2489 - acc: 0.9050\n",
      "Epoch 396/500\n",
      "2000/2000 [==============================] - 1s 397us/step - loss: 0.2570 - acc: 0.9045\n",
      "Epoch 397/500\n",
      "2000/2000 [==============================] - 1s 396us/step - loss: 0.2528 - acc: 0.9075\n",
      "Epoch 398/500\n",
      "2000/2000 [==============================] - 1s 401us/step - loss: 0.2514 - acc: 0.9050\n",
      "Epoch 399/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.2514 - acc: 0.9055\n",
      "Epoch 400/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2482 - acc: 0.9070\n",
      "Epoch 401/500\n",
      "2000/2000 [==============================] - 1s 372us/step - loss: 0.2577 - acc: 0.9115\n",
      "Epoch 402/500\n",
      "2000/2000 [==============================] - 1s 359us/step - loss: 0.2534 - acc: 0.9055\n",
      "Epoch 403/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2515 - acc: 0.9035\n",
      "Epoch 404/500\n",
      "2000/2000 [==============================] - 1s 356us/step - loss: 0.2486 - acc: 0.9040\n",
      "Epoch 405/500\n",
      "2000/2000 [==============================] - 1s 371us/step - loss: 0.2499 - acc: 0.9060\n",
      "Epoch 406/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.2492 - acc: 0.9085\n",
      "Epoch 407/500\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.2460 - acc: 0.9070\n",
      "Epoch 408/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2499 - acc: 0.9070\n",
      "Epoch 409/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2484 - acc: 0.9110\n",
      "Epoch 410/500\n",
      "2000/2000 [==============================] - 1s 438us/step - loss: 0.2547 - acc: 0.9050\n",
      "Epoch 411/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.2507 - acc: 0.9050\n",
      "Epoch 412/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2520 - acc: 0.9080\n",
      "Epoch 413/500\n",
      "2000/2000 [==============================] - 1s 370us/step - loss: 0.2491 - acc: 0.9020\n",
      "Epoch 414/500\n",
      "2000/2000 [==============================] - 1s 358us/step - loss: 0.2500 - acc: 0.9095\n",
      "Epoch 415/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2584 - acc: 0.9050\n",
      "Epoch 416/500\n",
      "2000/2000 [==============================] - 1s 376us/step - loss: 0.2540 - acc: 0.9055\n",
      "Epoch 417/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2475 - acc: 0.9045\n",
      "Epoch 418/500\n",
      "2000/2000 [==============================] - 1s 362us/step - loss: 0.2472 - acc: 0.9050\n",
      "Epoch 419/500\n",
      "2000/2000 [==============================] - 1s 375us/step - loss: 0.2456 - acc: 0.9110\n",
      "Epoch 420/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2512 - acc: 0.9120\n",
      "Epoch 421/500\n",
      "2000/2000 [==============================] - 1s 361us/step - loss: 0.2499 - acc: 0.9110\n",
      "Epoch 422/500\n",
      "2000/2000 [==============================] - 1s 372us/step - loss: 0.2436 - acc: 0.9115\n",
      "Epoch 423/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2437 - acc: 0.9130\n",
      "Epoch 424/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2489 - acc: 0.9125\n",
      "Epoch 425/500\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.2480 - acc: 0.9080\n",
      "Epoch 426/500\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.2526 - acc: 0.9085\n",
      "Epoch 427/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2493 - acc: 0.9105 0s - loss: 0.2928 \n",
      "Epoch 428/500\n",
      "2000/2000 [==============================] - 1s 372us/step - loss: 0.2460 - acc: 0.9130\n",
      "Epoch 429/500\n",
      "2000/2000 [==============================] - 1s 363us/step - loss: 0.2485 - acc: 0.9055\n",
      "Epoch 430/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.2535 - acc: 0.9055\n",
      "Epoch 431/500\n",
      "2000/2000 [==============================] - 1s 435us/step - loss: 0.2460 - acc: 0.9085\n",
      "Epoch 432/500\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.2485 - acc: 0.9135\n",
      "Epoch 433/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2457 - acc: 0.9075\n",
      "Epoch 434/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2511 - acc: 0.9050 0s - loss: 0.1959 \n",
      "Epoch 435/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2469 - acc: 0.9095\n",
      "Epoch 436/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2484 - acc: 0.9100\n",
      "Epoch 437/500\n",
      "2000/2000 [==============================] - 1s 364us/step - loss: 0.2467 - acc: 0.9065\n",
      "Epoch 438/500\n",
      "2000/2000 [==============================] - 1s 436us/step - loss: 0.2452 - acc: 0.9125\n",
      "Epoch 439/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2529 - acc: 0.9025\n",
      "Epoch 440/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.2477 - acc: 0.9065\n",
      "Epoch 441/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2454 - acc: 0.9045\n",
      "Epoch 442/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2458 - acc: 0.9055\n",
      "Epoch 443/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.2467 - acc: 0.9105\n",
      "Epoch 444/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2441 - acc: 0.9070\n",
      "Epoch 445/500\n",
      "2000/2000 [==============================] - 1s 419us/step - loss: 0.2455 - acc: 0.9010\n",
      "Epoch 446/500\n",
      "2000/2000 [==============================] - 1s 403us/step - loss: 0.2463 - acc: 0.9095\n",
      "Epoch 447/500\n",
      "2000/2000 [==============================] - 1s 384us/step - loss: 0.2519 - acc: 0.9070\n",
      "Epoch 448/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2461 - acc: 0.9100\n",
      "Epoch 449/500\n",
      "2000/2000 [==============================] - 1s 390us/step - loss: 0.2467 - acc: 0.9075\n",
      "Epoch 450/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2451 - acc: 0.9110\n",
      "Epoch 451/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2423 - acc: 0.9120\n",
      "Epoch 452/500\n",
      "2000/2000 [==============================] - 1s 443us/step - loss: 0.2450 - acc: 0.9090\n",
      "Epoch 453/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.2468 - acc: 0.9110\n",
      "Epoch 454/500\n",
      "2000/2000 [==============================] - 1s 385us/step - loss: 0.2525 - acc: 0.9060\n",
      "Epoch 455/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2479 - acc: 0.9085\n",
      "Epoch 456/500\n",
      "2000/2000 [==============================] - 1s 372us/step - loss: 0.2495 - acc: 0.9105\n",
      "Epoch 457/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2532 - acc: 0.9040\n",
      "Epoch 458/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.2439 - acc: 0.9120\n",
      "Epoch 459/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2424 - acc: 0.9120\n",
      "Epoch 460/500\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.2435 - acc: 0.9110\n",
      "Epoch 461/500\n",
      "2000/2000 [==============================] - 1s 379us/step - loss: 0.2503 - acc: 0.9080\n",
      "Epoch 462/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2470 - acc: 0.9090\n",
      "Epoch 463/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2508 - acc: 0.9020\n",
      "Epoch 464/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2495 - acc: 0.9045\n",
      "Epoch 465/500\n",
      "2000/2000 [==============================] - 1s 382us/step - loss: 0.2444 - acc: 0.9125\n",
      "Epoch 466/500\n",
      "2000/2000 [==============================] - 1s 378us/step - loss: 0.2434 - acc: 0.9075\n",
      "Epoch 467/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2469 - acc: 0.9065\n",
      "Epoch 468/500\n",
      "2000/2000 [==============================] - 1s 391us/step - loss: 0.2418 - acc: 0.9100\n",
      "Epoch 469/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.2410 - acc: 0.9125\n",
      "Epoch 470/500\n",
      "2000/2000 [==============================] - 1s 380us/step - loss: 0.2443 - acc: 0.9100 0s - loss: 0.2772\n",
      "Epoch 471/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2454 - acc: 0.9145\n",
      "Epoch 472/500\n",
      "2000/2000 [==============================] - 1s 408us/step - loss: 0.2492 - acc: 0.9035\n",
      "Epoch 473/500\n",
      "2000/2000 [==============================] - 1s 429us/step - loss: 0.2398 - acc: 0.9120\n",
      "Epoch 474/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2413 - acc: 0.9130\n",
      "Epoch 475/500\n",
      "2000/2000 [==============================] - 1s 396us/step - loss: 0.2460 - acc: 0.9075\n",
      "Epoch 476/500\n",
      "2000/2000 [==============================] - 1s 386us/step - loss: 0.2471 - acc: 0.9090\n",
      "Epoch 477/500\n",
      "2000/2000 [==============================] - 1s 388us/step - loss: 0.2418 - acc: 0.9110\n",
      "Epoch 478/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 434us/step - loss: 0.2455 - acc: 0.9145\n",
      "Epoch 479/500\n",
      "2000/2000 [==============================] - 1s 416us/step - loss: 0.2481 - acc: 0.9065\n",
      "Epoch 480/500\n",
      "2000/2000 [==============================] - 1s 373us/step - loss: 0.2402 - acc: 0.9085\n",
      "Epoch 481/500\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.2423 - acc: 0.9155\n",
      "Epoch 482/500\n",
      "2000/2000 [==============================] - 1s 375us/step - loss: 0.2428 - acc: 0.9070\n",
      "Epoch 483/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.2413 - acc: 0.9130\n",
      "Epoch 484/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.2442 - acc: 0.9125\n",
      "Epoch 485/500\n",
      "2000/2000 [==============================] - 1s 382us/step - loss: 0.2445 - acc: 0.9110\n",
      "Epoch 486/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2433 - acc: 0.9090\n",
      "Epoch 487/500\n",
      "2000/2000 [==============================] - 1s 369us/step - loss: 0.2442 - acc: 0.9075\n",
      "Epoch 488/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2559 - acc: 0.9080\n",
      "Epoch 489/500\n",
      "2000/2000 [==============================] - 1s 377us/step - loss: 0.2437 - acc: 0.9060\n",
      "Epoch 490/500\n",
      "2000/2000 [==============================] - 1s 381us/step - loss: 0.2382 - acc: 0.9150\n",
      "Epoch 491/500\n",
      "2000/2000 [==============================] - 1s 383us/step - loss: 0.2358 - acc: 0.9135\n",
      "Epoch 492/500\n",
      "2000/2000 [==============================] - 1s 420us/step - loss: 0.2448 - acc: 0.9105 0s - loss: 0.216\n",
      "Epoch 493/500\n",
      "2000/2000 [==============================] - 1s 512us/step - loss: 0.2425 - acc: 0.9070\n",
      "Epoch 494/500\n",
      "2000/2000 [==============================] - 1s 443us/step - loss: 0.2432 - acc: 0.9090\n",
      "Epoch 495/500\n",
      "2000/2000 [==============================] - 1s 366us/step - loss: 0.2438 - acc: 0.9115\n",
      "Epoch 496/500\n",
      "2000/2000 [==============================] - 1s 374us/step - loss: 0.2399 - acc: 0.9090\n",
      "Epoch 497/500\n",
      "2000/2000 [==============================] - 1s 422us/step - loss: 0.2407 - acc: 0.9070\n",
      "Epoch 498/500\n",
      "2000/2000 [==============================] - 1s 427us/step - loss: 0.2418 - acc: 0.9120\n",
      "Epoch 499/500\n",
      "2000/2000 [==============================] - 1s 440us/step - loss: 0.2441 - acc: 0.9065\n",
      "Epoch 500/500\n",
      "2000/2000 [==============================] - 1s 411us/step - loss: 0.2386 - acc: 0.9145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24cad90dbe0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "                   \n",
    "model.fit(featureTrainSelection, y_train,epochs=500, batch_size=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pima-weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333/1333 [==============================] - 0s 270us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34276564769161794, 0.881470366787034]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(featureTestSelection, y_test, batch_size=150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
